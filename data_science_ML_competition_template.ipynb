{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558850fc",
   "metadata": {},
   "source": [
    "# Internship competition: Predict the correct house prices!\n",
    "\n",
    "## Fictitious assignment\n",
    "An online platform for buying and selling apartments wants to develop an app to attract more potential sellers. The app should reliably predict the\n",
    "selling price based on some key data about an apartment. \n",
    "\n",
    "\n",
    "Everyone will receive\n",
    "- `house_price_data.csv`, a data set with features/variables for different houses and the label (here: house price). This can be used to train and test models.\n",
    "- `house_price_data_unknown.csv` is a data set with houses for which the price is unknown.\n",
    "\n",
    "## Goal: Predict house prices as accurately as possible\n",
    "At the end, all teams should submit their price predictions for the houses in `house_price_data_unknown.csv`. After submission, the predictions will be compared with the actual values (using MAE, mean absolute error). The team with the most accurate predictions (according to the MAE value) wins :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adab781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0222ad",
   "metadata": {},
   "source": [
    "# Let's get started... Import and explore data\n",
    "\n",
    "- As always, import the data using `pd.read_csv` (`house_price_data.csv`)\n",
    "- The column `price` contains our label (or target variable).\n",
    "- Are there any missing values?\n",
    "- Are there any outliers/incorrect/strange entries?\n",
    "\n",
    "--> `.describe()` & `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:\\Users\\Sander\\Repos\\DataScience\\Data\\Daten für Machine Learning Competition-20250528\\house_price_data.csv\"  # set to your own path\n",
    "\n",
    "data = pd.read_csv(filename)\n",
    "data = data.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5bc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab27a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749a141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82759176",
   "metadata": {},
   "source": [
    "## Graphical overview over all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34443d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(15, 15), bins=15, rwidth=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c4ec27",
   "metadata": {},
   "source": [
    "## Correlations!?\n",
    "- Are there meaningful correlations with our target label (`price`)? If so, does this make us confident that we can train a model to predict the price?\n",
    "- Are there any features with suspiciously high (or low) correlations that could be a sign of duplication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ee18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 10))\n",
    "\n",
    "sb.heatmap(\n",
    "    data.corr(),\n",
    "    annot=True, cmap=\"PuOr\",fmt=\".1f\",\n",
    "    vmin=-1, vmax=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93756440",
   "metadata": {},
   "source": [
    "# Data cleaning & division data --> X, y\n",
    "- Remove missing values (if any)\n",
    "- Remove columns that are not to be used by the machine learning models.\n",
    "(e.g. with `.drop(..., axis=1)`)\n",
    "- Convert columns that contain categories (depending on the model).\n",
    "- Split the data into `X` (without the label) and `y` (only the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d616849",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"waterfront\"], axis=1)\n",
    "X = data.drop([\"price\"], axis=1)\n",
    "y = data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51bd9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a91430f7",
   "metadata": {},
   "source": [
    "# Searching for the \"right\" model...\n",
    "\n",
    "This is about a regression model. There are many options! See, for example, https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "Possible candidates would be:\n",
    "\n",
    "- `sklearn.linear_model import LinearRegression`\n",
    "- `sklearn.tree.DecisionTreeRegressor`\n",
    "- `sklearn.neighbors.KNeighborsRegressor`\n",
    "- `sklearn.ensemble.RandomForestRegressor`\n",
    "\n",
    "**Caution: Please do not use any of the neural networks from Scikit-Learn.**\n",
    "\n",
    "## Warning: Some of the models may require a lot of time for training (or even prediction).\n",
    "(Therefore, it is better to work on several computers in a team)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e2a24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick guide to using Scikit-Learn models\n",
    "\n",
    "### General procedure: Initialize, train, predict\n",
    "The models in Scikit-Learn are always executed according to the same principle.\n",
    "\n",
    "1) Create object: `my_model = SomeFancyModel(parameter1=4, ...)` \n",
    "2) Train model: `my_model.fit(X, y)`\n",
    "3) Make predictions: `my_model.predict(X_new)`\n",
    "\n",
    "### Model parameters – which ones are there?\n",
    "\n",
    "We get a list of all modifiable parameters via `my_model.get_params()` (this also works for pipelines).\n",
    "\n",
    "However, to understand exactly what each parameter does, we need to look at the Scikit-Learn documentation (https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "### Pipelines\n",
    "\n",
    "In Scikit-Learn, the various processing steps can be linked in a pipeline. This makes sense if data processing is part of the model, for example if the data needs to be scaled. Here is an example:\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "(\"scale\", StandardScaler()),\n",
    "(\"model\", KNeighborsRegressor())\n",
    "])\n",
    "```\n",
    "A pipeline object is then treated like a model, i.e., training is done with `pipe.fit()` and prediction with `pipe.predict()`.\n",
    "\n",
    "\n",
    "### Grid search\n",
    "To test multiple conditions of a model (or pipeline), a so-called \"grid search\" is useful, i.e., simply running through all possible parameter combinations.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "```python\n",
    "grid = GridSearchCV(estimator=my_model,\n",
    "param_grid={\n",
    "‘parameter_whatever’: [3, 5, 7]\n",
    "},\n",
    "cv=3,\n",
    "verbose=2)\n",
    "```\n",
    "\n",
    "A GridSearchCV object is then treated similarly to a model, i.e., training is done with `grid.fit()`. We get the results of the search via `grid.cv_results_` (Python dictionary), or to display them a little better via `pd.DataFrame(grid.cv_results_)`.\n",
    "\n",
    "Multiple parameters can also be tested simultaneously, in which case all combinations are trained and tested accordingly.\n",
    "\n",
    "Other information about grid search:\n",
    "- `cv` stands for *cross validation*.\n",
    "- `verbose` specifies how much information should be output during training (default is 0, which outputs nothing; slightly more information is provided in ascending order with 1, 2, 3).\n",
    "\n",
    "### Grid search scoring\n",
    "\n",
    "If nothing else is specified, GridSearch simply uses a metric that is specified by default for the respective model type. However, this can vary greatly depending on the model. If different models are to be compared with each other, it is often necessary to specify a common \"score.\" This can be done as follows:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "grid = GridSearchCV(estimator=my_model,\n",
    "param_grid={\n",
    "‘model__whatever’: [5, 10, 20]\n",
    "},\n",
    "scoring={\"MAE\": make_scorer(mean_absolute_error,\n",
    "greater_is_better=False)},\n",
    "cv=3, refit=\"MAE\")\n",
    "```\n",
    "\n",
    "### Explore results\n",
    "\n",
    "One option is a scatter plot:\n",
    "```python\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.scatter(y_test, pipe.predict(X_test), alpha=0.25)\n",
    "ax.set_xlabel(\"True values\")\n",
    "ax.set_ylabel(\"Predicted values\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bdabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c394be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97405dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f7f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b6ef314",
   "metadata": {},
   "source": [
    "---\n",
    "# Finally: the test!\n",
    "\n",
    "Once the appropriate model and parameters have been found, predictions can be made on the unknown test data!\n",
    "\n",
    "These are located in the file `house_price_data_unknowns.csv`.\n",
    "\n",
    "Most of the code for this is in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"datasets/house_price_data_unknowns.csv\"\n",
    "\n",
    "data_competition = pd.read_csv(filename).dropna()\n",
    "data_competition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf472b",
   "metadata": {},
   "source": [
    "## Make your FINAL predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989895b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = my_model.predict(data_competition.drop([\"id\"], axis=1))\n",
    "predicted_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c100cd",
   "metadata": {},
   "source": [
    "## Create your FINAL results!\n",
    "Hier ordnen wir nur die Vorhersagen den \"id\" zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_results = pd.DataFrame({\"id\": data_competition[\"id\"],\n",
    "                                    \"price\": predicted_prices})\n",
    "competition_results                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59087e",
   "metadata": {},
   "source": [
    "## Save results! (and when done --> upload on Moodle)\n",
    "- Should be obvious, but: **please replace `name1_name2` by your names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1da694",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"house_price_predictions_name1_name2.csv\"\n",
    "\n",
    "competition_results.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4627d",
   "metadata": {},
   "source": [
    "### Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f1f7d-99ab-4784-b64c-a4e18630b20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
