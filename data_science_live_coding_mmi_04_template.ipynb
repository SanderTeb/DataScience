{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2075c37",
   "metadata": {},
   "source": [
    "# Live Coding: Clustering - Searching for Customer Profiles\n",
    "\n",
    "After finishing this notebook, here some more ideas on how to work on this: https://www.kaggle.com/code/karnikakapoor/customer-segmentation-clustering/notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7cfad",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "This dataset (again) comes from Kaggle: https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers.\n",
    "\n",
    "Customer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company’s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment.\n",
    "\n",
    "### Attributes\n",
    "\n",
    "People\n",
    "\n",
    "    ID: Customer's unique identifier\n",
    "    Year_Birth: Customer's birth year\n",
    "    Education: Customer's education level\n",
    "    Marital_Status: Customer's marital status\n",
    "    Income: Customer's yearly household income\n",
    "    Kidhome: Number of children in customer's household\n",
    "    Teenhome: Number of teenagers in customer's household\n",
    "    Dt_Customer: Date of customer's enrollment with the company\n",
    "    Recency: Number of days since customer's last purchase\n",
    "    Complain: 1 if the customer complained in the last 2 years, 0 otherwise\n",
    "\n",
    "Products\n",
    "\n",
    "    MntWines: Amount spent on wine in last 2 years\n",
    "    MntFruits: Amount spent on fruits in last 2 years\n",
    "    MntMeatProducts: Amount spent on meat in last 2 years\n",
    "    MntFishProducts: Amount spent on fish in last 2 years\n",
    "    MntSweetProducts: Amount spent on sweets in last 2 years\n",
    "    MntGoldProds: Amount spent on gold in last 2 years\n",
    "\n",
    "Promotion\n",
    "\n",
    "    NumDealsPurchases: Number of purchases made with a discount\n",
    "    AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n",
    "    AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n",
    "    AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n",
    "    AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n",
    "    AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n",
    "    Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
    "\n",
    "Place\n",
    "\n",
    "    NumWebPurchases: Number of purchases made through the company’s website\n",
    "    NumCatalogPurchases: Number of purchases made using a catalogue\n",
    "    NumStorePurchases: Number of purchases made directly in stores\n",
    "    NumWebVisitsMonth: Number of visits to company’s website in the last month\n",
    "\n",
    "#### Target\n",
    "\n",
    "Need to perform clustering to summarize customer segments.\n",
    "\n",
    "#### Acknowledgement\n",
    "\n",
    "The dataset for this project is provided by Dr. Omar Romero-Hernandez. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da77ac4",
   "metadata": {},
   "source": [
    "## Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb  # data visualization library  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfed08",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "\n",
    "The data can be imported using Pandas with the command `pd.read_csv()`.\n",
    "In many cases, this does not work directly. This is usually due to one of the following issues:\n",
    "- `FileNotFoundError` --> Either the file name is spelled incorrectly or the path is incorrect.\n",
    "- `UnicodeDecodeError` --> Either the file name (+path) contains invalid characters (in Windows, for example, \"//\" must often be used instead of \"/\"), or the file itself is not saved in the expected \"encoding.\" For the latter, there are two options: (1) Convert the file using an editor. Or (2) set the parameter `encoding=...` accordingly. \n",
    "There are many possible encodings ([see link](https://docs.python.org/3/library/codecs.html#standard-encodings)), but the most common are \"utf-8\" (the standard), \"ANSI\" (on Mac: \"iso-8859-1\" or \"ISO8859\") or \"ASCII\".\n",
    "- `ParserError` --> Usually means that the \"delimiter\" (i.e., the separator) is specified incorrectly. It is best to open the file briefly with an editor and check, then set it accordingly with `delimiter=\"...\"`. Typical separators are `\",\"`, `\";\"`, `\"\\t\"` (tab).\n",
    "- If the file does not start with the desired column names, this can be corrected by specifying the rows to be skipped --> `skiprows=1` (1, 2, 3,... depending on the case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"datasets/marketing_campaign.csv\"  # adjust to your own path\n",
    "\n",
    "data = pd.read_csv(filename, sep= #add your code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49fffa",
   "metadata": {},
   "source": [
    "## (1) Exercise: Initial data exploration!\n",
    "Use Pandas to answer the following questions:\n",
    "\n",
    "- How many columns are there and what are they? --> `data.columns`\n",
    "- Are there any missing values? --> `.info()`\n",
    "- Initial overview and: Are there any unusual entries? --> `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836bd6d8",
   "metadata": {},
   "source": [
    "Use ID as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa59569",
   "metadata": {},
   "source": [
    "## Data pre-processing: Convert date\n",
    "This can be done in Pandas with `pd.to_datetime()`. Either the existing format can be described --> `format = '%d-%m-%Y'`\n",
    "\n",
    "Or we can simply try what Pandas \"guesses\" --> `infer_datetime_format=True`\n",
    "\n",
    "The date is then no longer a string (even if it looks like one when displayed!), but a separate `Timestamp` format.\n",
    "\n",
    "### Test it out:\n",
    "\n",
    "- What does `data[\"Dt_Customer\"][0].day` return?\n",
    "- What does `data[\"Dt_Customer\"][0].year` return?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2812d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"],\n",
    "                                     dayfirst=True, format = '%d-%m-%Y')\n",
    "                                     #infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42a034",
   "metadata": {},
   "source": [
    "## (1b) Further data exploration\n",
    "- Which features/characteristics have \"outliers\"?\n",
    "\n",
    "To answer this question, it is useful to display the features as a distribution using `plot(kind=\"hist\")` or directly with `.hist()`.\n",
    "\n",
    "Incidentally, this can even be done for all numerical features at once with `data.hist()`. However, the size should be adjusted using `figsize=(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329be0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8f1b36d",
   "metadata": {},
   "source": [
    "## (2) Data cleaning\n",
    "- Remove entries with missing values by using `.dropna()`.\n",
    "\n",
    "There are some outliers in the distributions/histograms. There are some entries in `Income` that deviate significantly from the rest. The age data also appears to be incorrect.\n",
    "- All data points with `Income` >= 150000 should be removed.\n",
    "- All data points with `Year_Birth` < 1925 should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23d564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f7234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e811a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc3a0d6f",
   "metadata": {},
   "source": [
    "## (3) Explore data\n",
    "- Explore the features \"Marital_Status\" and \"Education\" with `value_counts()`. This can also be done graphically with additional `.plot(kind=\"barh\")` or `.plot(kind=\"pie\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5566f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1edd743f",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Now we want to convert, remove, and add a few features...\n",
    "- Replace `Year_of_Birth` with a new feature `Age`, which is calculated using `2020 - Year_of_Birth`.\n",
    "- Add a new feature `Spent`, which contains the sum of all purchases:\n",
    "`'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases'`\n",
    "\n",
    "### Rename feature\n",
    "We would prefer to rename some features. To do this, please execute the following:\n",
    "```python\n",
    "data=data.rename(\n",
    "    columns={\n",
    "        \"MntWines\": \"Wines\",\n",
    "        \"MntFruits\":\"Fruits\",\n",
    "        \"MntMeatProducts\":\"Meat\",\n",
    "        \"MntFishProducts\":\"Fish\",\n",
    "        \"MntSweetProducts\":\"Sweets\",\n",
    "        \"MntGoldProds\":\"Gold\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### Remove features\n",
    "- The following features should be removed: \"Year_Birth\", \"Z_CostContact\", \"Z_Revenue\"\n",
    "\n",
    "You can remove them using `df = df.drop(list_of_cols_to_drop, axis=1)`, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b9f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acace4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15bd2a64",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "We can view all Pearson correlations using `data.corr()`.\n",
    "Given the number of correlations, it makes sense to display them graphically using\n",
    "\n",
    "```python\n",
    "sb.heatmap(data.corr())\n",
    "```\n",
    "\n",
    "### Make it look nicer:\n",
    "The plot will (probably) be a little easier to read if we display the values (`annot=True`).\n",
    "\n",
    "We can also select a different \"colormap\", see [matplotlib documentation](https://matplotlib.org/stable/tutorials/colors/colormaps.html).\n",
    "It is also good to set min and max values, which can be done by using `vmin` and `vmax`.\n",
    "\n",
    "### Exercise:\n",
    "- Display the correlation matrix graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800805f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "sb.heatmap(\n",
    "    data.corr(),\n",
    "    # annot=True,\n",
    "    # linewidths=.5,\n",
    "    cmap=#value\n",
    "    vmin=#value,\n",
    "    vmax= #value,\n",
    "    fmt= '.1f', ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe779e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "079f592a",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Now we can try k-Means by using [Scikit-Learn](https://scikit-learn.org/stable/modules/clustering.html).\n",
    "\n",
    "But before we run the clustering algorithm we need to process the data in certaing ways to make sure that the algorithm can run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60966e9a",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "\n",
    "For many ML/data science techniques, it is essential to scale the data appropriately. In this case, techniques that take absolute values into account would otherwise result in a strong bias toward \"large\" numbers, such as `Income`, etc.\n",
    "\n",
    "We will therefore standardize the values using the `StandardScaler` from the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a94d2-4401-4f9c-b0fe-ed5d71f8a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creating a copy of data (with only numerical values)\n",
    "data_numerical = data.copy().select_dtypes(include='number')\n",
    "\n",
    "# Creating a subset of dataframe by dropping the features on deals accepted and promotions\n",
    "cols_remove = ['AcceptedCmp3', 'AcceptedCmp4',\n",
    "               'AcceptedCmp5', 'AcceptedCmp1',\n",
    "               'AcceptedCmp2', 'Complain', 'Response']\n",
    "data_numerical = data_numerical.drop(cols_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0ecf5-3ad0-4d26-a4d8-99616c52be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "# add code to scale your data --> use scikit-learn StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1854ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532237c0",
   "metadata": {},
   "source": [
    "## K-means\n",
    "- here with 4 clusters as default!\n",
    "\n",
    "The import is done via `from sklearn.cluster import KMeans`.\n",
    "Then the algorithm must be run on the data with `.fit()`:\n",
    "`kmeans = KMeans(...).fit(data_scaled)`\n",
    "\n",
    "As parameters, we must add at least `n_clusters=...`. It is also better to add `random_state=...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b609f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "536d755b",
   "metadata": {},
   "source": [
    "## Inspect the results visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.barplot(x='cluster',y='Age', data=data)\n",
    "plt.title(\"Age / Cluster\")\n",
    "plt.show()\n",
    "\n",
    "sb.barplot(x='cluster',y='Income', data=data)\n",
    "plt.title(\"Income / Cluster\")\n",
    "plt.show()\n",
    "\n",
    "sb.barplot(x='cluster',y='Kidhome', data=data)\n",
    "plt.title(\"Kids / Cluster\")\n",
    "plt.show()\n",
    "\n",
    "sb.barplot(x='cluster',y='Teenhome', data=data)\n",
    "plt.title(\"Teens / Cluster\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
